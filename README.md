# Class Imbalance Handling in Machine Learning

This repository presents a comparative study of different **sampling techniques**
for handling class imbalance and their impact on various machine learning models.

## ğŸ“Š Sampling Techniques
- No Sampling (Baseline)
- Random Under Sampling
- Random Over Sampling
- SMOTE
- NearMiss

## ğŸ¤– Models Used
- Logistic Regression
- Support Vector Machine (SVM)
- Random Forest
- Gradient Boosting

## ğŸ“ˆ Evaluation Metrics
- Accuracy
- F1-score
- ROC-AUC

## ğŸ† Key Finding
Tree-based models combined with **Random Over-Sampling and SMOTE**
achieved the highest accuracy and better class separation
for the imbalanced fraud detection dataset.

## ğŸ“ Project Structure
